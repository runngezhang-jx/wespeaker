

<!DOCTYPE html>
<html class="writer-html5" lang="en">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Papers Implemented in WeSpeaker &mdash; wespeaker 1.2.0 documentation</title>
      <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=b86133f3" />
      <link rel="stylesheet" type="text/css" href="_static/css/theme.css?v=e59714d7" />

  
      <script src="_static/jquery.js?v=5d32c60e"></script>
      <script src="_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js?v=4c8675c2"></script>
      <script src="_static/doctools.js?v=888ff710"></script>
      <script src="_static/sphinx_highlight.js?v=4825356b"></script>
      <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Python API Reference" href="python_api/modules.html" />
    <link rel="prev" title="Speaker Recognition Papers" href="speaker_recognition_papers.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="index.html" class="icon icon-home">
            wespeaker
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="python_package.html">Python Package</a></li>
<li class="toctree-l1"><a class="reference internal" href="train.html">How to train models?</a></li>
<li class="toctree-l1"><a class="reference internal" href="pretrained.html">Pretrained Models in Wespeaker</a></li>
<li class="toctree-l1"><a class="reference internal" href="runtime.html">Runtime for Wespeaker</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="reference.html">Reference</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="paper.html">Wespeaker Papers</a></li>
<li class="toctree-l2"><a class="reference internal" href="speaker_recognition_papers.html">Speaker Recognition Papers</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">Papers Implemented in WeSpeaker</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#stay-tuned-need-to-add-a-introduction-for-each-paper">Stay Tuned! (Need to add a introduction for each paper)</a></li>
<li class="toctree-l3"><a class="reference internal" href="#introduction">Introduction</a></li>
<li class="toctree-l3"><a class="reference internal" href="#architecture">Architecture</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#tdnn">TDNN</a></li>
<li class="toctree-l4"><a class="reference internal" href="#ecapa-tdnn">ECAPA-TDNN</a></li>
<li class="toctree-l4"><a class="reference internal" href="#xi-vector">Xi-vector</a></li>
<li class="toctree-l4"><a class="reference internal" href="#resnet">ResNet</a></li>
<li class="toctree-l4"><a class="reference internal" href="#redimnet">ReDimNet</a></li>
<li class="toctree-l4"><a class="reference internal" href="#golden-gemini-df-resnet">Golden gemini DF-ResNet</a></li>
<li class="toctree-l4"><a class="reference internal" href="#simam-resnet">SimAM-ResNet</a></li>
<li class="toctree-l4"><a class="reference internal" href="#whisper-based-speaker-verification">Whisper based Speaker Verification</a></li>
<li class="toctree-l4"><a class="reference internal" href="#cam">CAM++</a></li>
<li class="toctree-l4"><a class="reference internal" href="#eres2net">ERes2Net</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#pipelines">Pipelines</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#dino-pretraining-with-large-scale-data">DINO Pretraining with Large-scale Data</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#dataset">Dataset</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#voxblink">VoxBlink</a></li>
<li class="toctree-l4"><a class="reference internal" href="#voxceleb">VoxCeleb</a></li>
<li class="toctree-l4"><a class="reference internal" href="#cnceleb">CNCeleb</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="python_api/modules.html">Python API Reference</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="contribute.html">Contributing to Wespeaker</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">wespeaker</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="reference.html">Reference</a></li>
      <li class="breadcrumb-item active">Papers Implemented in WeSpeaker</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/papers_using_wespeaker.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="papers-implemented-in-wespeaker">
<h1>Papers Implemented in WeSpeaker<a class="headerlink" href="#papers-implemented-in-wespeaker" title="Permalink to this heading"></a></h1>
<p>[TOC]</p>
<section id="stay-tuned-need-to-add-a-introduction-for-each-paper">
<h2>Stay Tuned! (Need to add a introduction for each paper)<a class="headerlink" href="#stay-tuned-need-to-add-a-introduction-for-each-paper" title="Permalink to this heading"></a></h2>
</section>
<section id="introduction">
<h2>Introduction<a class="headerlink" href="#introduction" title="Permalink to this heading"></a></h2>
<p>After the release of the WeSpeaker project, many users from both academia and industry have actively engaged with it in their research. We appreciate all the feedback and contributions from the community and would like to highlight these interesting works.</p>
<p>Besides the citation of WeSpeaker itself, we highly recommend you to read and cite the corresponding papers as listed below.</p>
<div class="highlight-bibtex notranslate"><div class="highlight"><pre><span></span><span class="nc">@article</span><span class="p">{</span><span class="nl">wang2024advancing</span><span class="p">,</span>
<span class="w">  </span><span class="na">title</span><span class="p">=</span><span class="s">{Advancing speaker embedding learning: Wespeaker toolkit for research and production}</span><span class="p">,</span>
<span class="w">  </span><span class="na">author</span><span class="p">=</span><span class="s">{Wang, Shuai and Chen, Zhengyang and Han, Bing and Wang, Hongji and Liang, Chengdong and Zhang, Binbin and Xiang, Xu and Ding, Wen and Rohdin, Johan and Silnova, Anna and others}</span><span class="p">,</span>
<span class="w">  </span><span class="na">journal</span><span class="p">=</span><span class="s">{Speech Communication}</span><span class="p">,</span>
<span class="w">  </span><span class="na">volume</span><span class="p">=</span><span class="s">{162}</span><span class="p">,</span>
<span class="w">  </span><span class="na">pages</span><span class="p">=</span><span class="s">{103104}</span><span class="p">,</span>
<span class="w">  </span><span class="na">year</span><span class="p">=</span><span class="s">{2024}</span><span class="p">,</span>
<span class="w">  </span><span class="na">publisher</span><span class="p">=</span><span class="s">{Elsevier}</span>
<span class="p">}</span>

<span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">wang2023wespeaker</span><span class="p">,</span>
<span class="w">  </span><span class="na">title</span><span class="p">=</span><span class="s">{Wespeaker: A research and production oriented speaker embedding learning toolkit}</span><span class="p">,</span>
<span class="w">  </span><span class="na">author</span><span class="p">=</span><span class="s">{Wang, Hongji and Liang, Chengdong and Wang, Shuai and Chen, Zhengyang and Zhang, Binbin and Xiang, Xu and Deng, Yanlei and Qian, Yanmin}</span><span class="p">,</span>
<span class="w">  </span><span class="na">booktitle</span><span class="p">=</span><span class="s">{IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}</span><span class="p">,</span>
<span class="w">  </span><span class="na">pages</span><span class="p">=</span><span class="s">{1--5}</span><span class="p">,</span>
<span class="w">  </span><span class="na">year</span><span class="p">=</span><span class="s">{2023}</span><span class="p">,</span>
<span class="w">  </span><span class="na">organization</span><span class="p">=</span><span class="s">{IEEE}</span>
<span class="p">}</span>
</pre></div>
</div>
</section>
<section id="architecture">
<h2>Architecture<a class="headerlink" href="#architecture" title="Permalink to this heading"></a></h2>
<section id="tdnn">
<h3>TDNN<a class="headerlink" href="#tdnn" title="Permalink to this heading"></a></h3>
<div class="highlight-bibtex notranslate"><div class="highlight"><pre><span></span><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">snyder2018x</span><span class="p">,</span>
<span class="w">  </span><span class="na">title</span><span class="p">=</span><span class="s">{X-vectors: Robust dnn embeddings for speaker recognition}</span><span class="p">,</span>
<span class="w">  </span><span class="na">author</span><span class="p">=</span><span class="s">{Snyder, David and Garcia-Romero, Daniel and Sell, Gregory and Povey, Daniel and Khudanpur, Sanjeev}</span><span class="p">,</span>
<span class="w">  </span><span class="na">booktitle</span><span class="p">=</span><span class="s">{2018 IEEE international conference on acoustics, speech and signal processing (ICASSP)}</span><span class="p">,</span>
<span class="w">  </span><span class="na">pages</span><span class="p">=</span><span class="s">{5329--5333}</span><span class="p">,</span>
<span class="w">  </span><span class="na">year</span><span class="p">=</span><span class="s">{2018}</span><span class="p">,</span>
<span class="w">  </span><span class="na">organization</span><span class="p">=</span><span class="s">{IEEE}</span>
<span class="p">}</span>
</pre></div>
</div>
</section>
<section id="ecapa-tdnn">
<h3>ECAPA-TDNN<a class="headerlink" href="#ecapa-tdnn" title="Permalink to this heading"></a></h3>
<div class="highlight-bibtex notranslate"><div class="highlight"><pre><span></span><span class="nc">@article</span><span class="p">{</span><span class="nl">desplanques2020ecapa</span><span class="p">,</span>
<span class="w">  </span><span class="na">title</span><span class="p">=</span><span class="s">{Ecapa-tdnn: Emphasized channel attention, propagation and aggregation in tdnn based speaker verification}</span><span class="p">,</span>
<span class="w">  </span><span class="na">author</span><span class="p">=</span><span class="s">{Desplanques, Brecht and Thienpondt, Jenthe and Demuynck, Kris}</span><span class="p">,</span>
<span class="w">  </span><span class="na">journal</span><span class="p">=</span><span class="s">{arXiv preprint arXiv:2005.07143}</span><span class="p">,</span>
<span class="w">  </span><span class="na">year</span><span class="p">=</span><span class="s">{2020}</span>
<span class="p">}</span>
</pre></div>
</div>
</section>
<section id="xi-vector">
<h3>Xi-vector<a class="headerlink" href="#xi-vector" title="Permalink to this heading"></a></h3>
<div class="highlight-bibtex notranslate"><div class="highlight"><pre><span></span><span class="nc">@article</span><span class="p">{</span><span class="nl">lee2021xi</span><span class="p">,</span>
<span class="w">  </span><span class="na">title</span><span class="p">=</span><span class="s">{Xi-vector embedding for speaker recognition}</span><span class="p">,</span>
<span class="w">  </span><span class="na">author</span><span class="p">=</span><span class="s">{Lee, Kong Aik and Wang, Qiongqiong and Koshinaka, Takafumi}</span><span class="p">,</span>
<span class="w">  </span><span class="na">journal</span><span class="p">=</span><span class="s">{IEEE Signal Processing Letters}</span><span class="p">,</span>
<span class="w">  </span><span class="na">volume</span><span class="p">=</span><span class="s">{28}</span><span class="p">,</span>
<span class="w">  </span><span class="na">pages</span><span class="p">=</span><span class="s">{1385--1389}</span><span class="p">,</span>
<span class="w">  </span><span class="na">year</span><span class="p">=</span><span class="s">{2021}</span><span class="p">,</span>
<span class="w">  </span><span class="na">publisher</span><span class="p">=</span><span class="s">{IEEE}</span>
<span class="p">}</span>
</pre></div>
</div>
</section>
<section id="resnet">
<h3>ResNet<a class="headerlink" href="#resnet" title="Permalink to this heading"></a></h3>
<p>The Current ResNet implementation is based on our system for VoxSRC2019, it’s also the default speaker model in Pyannote.audio diarization pipeline (https://huggingface.co/pyannote/wespeaker-voxceleb-resnet34-LM)</p>
<div class="highlight-bibtex notranslate"><div class="highlight"><pre><span></span><span class="nc">@article</span><span class="p">{</span><span class="nl">zeinali2019but</span><span class="p">,</span>
<span class="w">  </span><span class="na">title</span><span class="p">=</span><span class="s">{But system description to voxceleb speaker recognition challenge 2019}</span><span class="p">,</span>
<span class="w">  </span><span class="na">author</span><span class="p">=</span><span class="s">{Zeinali, Hossein and Wang, Shuai and Silnova, Anna and Mat{\v{e}}jka, Pavel and Plchot, Old{\v{r}}ich}</span><span class="p">,</span>
<span class="w">  </span><span class="na">journal</span><span class="p">=</span><span class="s">{arXiv preprint arXiv:1910.12592}</span><span class="p">,</span>
<span class="w">  </span><span class="na">year</span><span class="p">=</span><span class="s">{2019}</span>
<span class="p">}</span>
</pre></div>
</div>
</section>
<section id="redimnet">
<h3>ReDimNet<a class="headerlink" href="#redimnet" title="Permalink to this heading"></a></h3>
<div class="highlight-bibtex notranslate"><div class="highlight"><pre><span></span><span class="nc">@article</span><span class="p">{</span><span class="nl">yakovlev2024reshape</span><span class="p">,</span>
<span class="w">  </span><span class="na">title</span><span class="p">=</span><span class="s">{Reshape Dimensions Network for Speaker Recognition}</span><span class="p">,</span>
<span class="w">  </span><span class="na">author</span><span class="p">=</span><span class="s">{Yakovlev, Ivan and Makarov, Rostislav and Balykin, Andrei and Malov, Pavel and Okhotnikov, Anton and Torgashov, Nikita}</span><span class="p">,</span>
<span class="w">  </span><span class="na">journal</span><span class="p">=</span><span class="s">{arXiv preprint arXiv:2407.18223}</span><span class="p">,</span>
<span class="w">  </span><span class="na">year</span><span class="p">=</span><span class="s">{2024}</span>
<span class="p">}</span>
</pre></div>
</div>
</section>
<section id="golden-gemini-df-resnet">
<h3>Golden gemini DF-ResNet<a class="headerlink" href="#golden-gemini-df-resnet" title="Permalink to this heading"></a></h3>
<div class="highlight-bibtex notranslate"><div class="highlight"><pre><span></span><span class="nc">@article</span><span class="p">{</span><span class="nl">liu2024golden</span><span class="p">,</span>
<span class="w">  </span><span class="na">title</span><span class="p">=</span><span class="s">{Golden gemini is all you need: Finding the sweet spots for speaker verification}</span><span class="p">,</span>
<span class="w">  </span><span class="na">author</span><span class="p">=</span><span class="s">{Liu, Tianchi and Lee, Kong Aik and Wang, Qiongqiong and Li, Haizhou}</span><span class="p">,</span>
<span class="w">  </span><span class="na">journal</span><span class="p">=</span><span class="s">{IEEE/ACM Transactions on Audio, Speech, and Language Processing}</span><span class="p">,</span>
<span class="w">  </span><span class="na">year</span><span class="p">=</span><span class="s">{2024}</span><span class="p">,</span>
<span class="w">  </span><span class="na">publisher</span><span class="p">=</span><span class="s">{IEEE}</span>
<span class="p">}</span>
</pre></div>
</div>
</section>
<section id="simam-resnet">
<h3>SimAM-ResNet<a class="headerlink" href="#simam-resnet" title="Permalink to this heading"></a></h3>
<div class="highlight-bibtex notranslate"><div class="highlight"><pre><span></span><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">qin2022simple</span><span class="p">,</span>
<span class="w">  </span><span class="na">title</span><span class="p">=</span><span class="s">{Simple attention module based speaker verification with iterative noisy label detection}</span><span class="p">,</span>
<span class="w">  </span><span class="na">author</span><span class="p">=</span><span class="s">{Qin, Xiaoyi and Li, Na and Weng, Chao and Su, Dan and Li, Ming}</span><span class="p">,</span>
<span class="w">  </span><span class="na">booktitle</span><span class="p">=</span><span class="s">{ICASSP 2022-2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}</span><span class="p">,</span>
<span class="w">  </span><span class="na">pages</span><span class="p">=</span><span class="s">{6722--6726}</span><span class="p">,</span>
<span class="w">  </span><span class="na">year</span><span class="p">=</span><span class="s">{2022}</span><span class="p">,</span>
<span class="w">  </span><span class="na">organization</span><span class="p">=</span><span class="s">{IEEE}</span>
<span class="p">}</span>
</pre></div>
</div>
</section>
<section id="whisper-based-speaker-verification">
<h3>Whisper based Speaker Verification<a class="headerlink" href="#whisper-based-speaker-verification" title="Permalink to this heading"></a></h3>
<div class="highlight-bibtex notranslate"><div class="highlight"><pre><span></span><span class="nc">@article</span><span class="p">{</span><span class="nl">zhao2024whisperpmfapartialmultiscalefeature</span><span class="p">,</span>
<span class="w">      </span><span class="na">title</span><span class="p">=</span><span class="s">{Whisper-PMFA: Partial Multi-Scale Feature Aggregation for Speaker Verification using Whisper Models}</span><span class="p">,</span>
<span class="w">      </span><span class="na">author</span><span class="p">=</span><span class="s">{Yiyang Zhao and Shuai Wang and Guangzhi Sun and Zehua Chen and Chao Zhang and Mingxing Xu and Thomas Fang Zheng}</span><span class="p">,</span>
<span class="w">      </span><span class="na">year</span><span class="p">=</span><span class="s">{2024}</span><span class="p">,</span>
<span class="w">      </span><span class="na">eprint</span><span class="p">=</span><span class="s">{2408.15585}</span><span class="p">,</span>
<span class="w">      </span><span class="na">archivePrefix</span><span class="p">=</span><span class="s">{arXiv}</span><span class="p">,</span>
<span class="w">      </span><span class="na">primaryClass</span><span class="p">=</span><span class="s">{cs.SD}</span><span class="p">,</span>
<span class="w">      </span><span class="na">url</span><span class="p">=</span><span class="s">{https://arxiv.org/abs/2408.15585}</span><span class="p">,</span>
<span class="p">}</span>
</pre></div>
</div>
</section>
<section id="cam">
<h3>CAM++<a class="headerlink" href="#cam" title="Permalink to this heading"></a></h3>
<div class="highlight-bibtex notranslate"><div class="highlight"><pre><span></span><span class="nc">@article</span><span class="p">{</span><span class="nl">wang2023cam++</span><span class="p">,</span>
<span class="w">  </span><span class="na">title</span><span class="p">=</span><span class="s">{Cam++: A fast and efficient network for speaker verification using context-aware masking}</span><span class="p">,</span>
<span class="w">  </span><span class="na">author</span><span class="p">=</span><span class="s">{Wang, Hui and Zheng, Siqi and Chen, Yafeng and Cheng, Luyao and Chen, Qian}</span><span class="p">,</span>
<span class="w">  </span><span class="na">journal</span><span class="p">=</span><span class="s">{arXiv preprint arXiv:2303.00332}</span><span class="p">,</span>
<span class="w">  </span><span class="na">year</span><span class="p">=</span><span class="s">{2023}</span>
<span class="p">}</span>
</pre></div>
</div>
</section>
<section id="eres2net">
<h3>ERes2Net<a class="headerlink" href="#eres2net" title="Permalink to this heading"></a></h3>
<div class="highlight-bibtex notranslate"><div class="highlight"><pre><span></span><span class="nc">@article</span><span class="p">{</span><span class="nl">chen2023enhanced</span><span class="p">,</span>
<span class="w">  </span><span class="na">title</span><span class="p">=</span><span class="s">{An enhanced res2net with local and global feature fusion for speaker verification}</span><span class="p">,</span>
<span class="w">  </span><span class="na">author</span><span class="p">=</span><span class="s">{Chen, Yafeng and Zheng, Siqi and Wang, Hui and Cheng, Luyao and Chen, Qian and Qi, Jiajun}</span><span class="p">,</span>
<span class="w">  </span><span class="na">journal</span><span class="p">=</span><span class="s">{arXiv preprint arXiv:2305.12838}</span><span class="p">,</span>
<span class="w">  </span><span class="na">year</span><span class="p">=</span><span class="s">{2023}</span>
<span class="p">}</span>
</pre></div>
</div>
</section>
</section>
<section id="pipelines">
<h2>Pipelines<a class="headerlink" href="#pipelines" title="Permalink to this heading"></a></h2>
<section id="dino-pretraining-with-large-scale-data">
<h3>DINO Pretraining with Large-scale Data<a class="headerlink" href="#dino-pretraining-with-large-scale-data" title="Permalink to this heading"></a></h3>
<div class="highlight-bibtex notranslate"><div class="highlight"><pre><span></span><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">wang2024leveraging</span><span class="p">,</span>
<span class="w">  </span><span class="na">title</span><span class="p">=</span><span class="s">{Leveraging In-the-Wild Data for Effective Self-Supervised Pretraining in Speaker Recognition}</span><span class="p">,</span>
<span class="w">  </span><span class="na">author</span><span class="p">=</span><span class="s">{Wang, Shuai and Bai, Qibing and Liu, Qi and Yu, Jianwei and Chen, Zhengyang and Han, Bing and Qian, Yanmin and Li, Haizhou}</span><span class="p">,</span>
<span class="w">  </span><span class="na">booktitle</span><span class="p">=</span><span class="s">{ICASSP 2024-2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}</span><span class="p">,</span>
<span class="w">  </span><span class="na">pages</span><span class="p">=</span><span class="s">{10901--10905}</span><span class="p">,</span>
<span class="w">  </span><span class="na">year</span><span class="p">=</span><span class="s">{2024}</span><span class="p">,</span>
<span class="w">  </span><span class="na">organization</span><span class="p">=</span><span class="s">{IEEE}</span>
<span class="p">}</span>
</pre></div>
</div>
</section>
</section>
<section id="dataset">
<h2>Dataset<a class="headerlink" href="#dataset" title="Permalink to this heading"></a></h2>
<section id="voxblink">
<h3>VoxBlink<a class="headerlink" href="#voxblink" title="Permalink to this heading"></a></h3>
<div class="highlight-bibtex notranslate"><div class="highlight"><pre><span></span><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">lin2024voxblink</span><span class="p">,</span>
<span class="w">  </span><span class="na">title</span><span class="p">=</span><span class="s">{Voxblink: A large scale speaker verification dataset on camera}</span><span class="p">,</span>
<span class="w">  </span><span class="na">author</span><span class="p">=</span><span class="s">{Lin, Yuke and Qin, Xiaoyi and Zhao, Guoqing and Cheng, Ming and Jiang, Ning and Wu, Haiying and Li, Ming}</span><span class="p">,</span>
<span class="w">  </span><span class="na">booktitle</span><span class="p">=</span><span class="s">{ICASSP 2024-2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}</span><span class="p">,</span>
<span class="w">  </span><span class="na">pages</span><span class="p">=</span><span class="s">{10271--10275}</span><span class="p">,</span>
<span class="w">  </span><span class="na">year</span><span class="p">=</span><span class="s">{2024}</span><span class="p">,</span>
<span class="w">  </span><span class="na">organization</span><span class="p">=</span><span class="s">{IEEE}</span>
<span class="p">}</span>

<span class="nc">@article</span><span class="p">{</span><span class="nl">lin2024voxblink2</span><span class="p">,</span>
<span class="w">  </span><span class="na">title</span><span class="p">=</span><span class="s">{VoxBlink2: A 100K+ Speaker Recognition Corpus and the Open-Set Speaker-Identification Benchmark}</span><span class="p">,</span>
<span class="w">  </span><span class="na">author</span><span class="p">=</span><span class="s">{Lin, Yuke and Cheng, Ming and Zhang, Fulin and Gao, Yingying and Zhang, Shilei and Li, Ming}</span><span class="p">,</span>
<span class="w">  </span><span class="na">journal</span><span class="p">=</span><span class="s">{arXiv preprint arXiv:2407.11510}</span><span class="p">,</span>
<span class="w">  </span><span class="na">year</span><span class="p">=</span><span class="s">{2024}</span>
<span class="p">}</span>
</pre></div>
</div>
</section>
<section id="voxceleb">
<h3>VoxCeleb<a class="headerlink" href="#voxceleb" title="Permalink to this heading"></a></h3>
<div class="highlight-bibtex notranslate"><div class="highlight"><pre><span></span><span class="nc">@article</span><span class="p">{</span><span class="nl">nagrani2017voxceleb</span><span class="p">,</span>
<span class="w">  </span><span class="na">title</span><span class="p">=</span><span class="s">{Voxceleb: a large-scale speaker identification dataset}</span><span class="p">,</span>
<span class="w">  </span><span class="na">author</span><span class="p">=</span><span class="s">{Nagrani, Arsha and Chung, Joon Son and Zisserman, Andrew}</span><span class="p">,</span>
<span class="w">  </span><span class="na">journal</span><span class="p">=</span><span class="s">{arXiv preprint arXiv:1706.08612}</span><span class="p">,</span>
<span class="w">  </span><span class="na">year</span><span class="p">=</span><span class="s">{2017}</span>
<span class="p">}</span>

<span class="nc">@article</span><span class="p">{</span><span class="nl">chung2018voxceleb2</span><span class="p">,</span>
<span class="w">  </span><span class="na">title</span><span class="p">=</span><span class="s">{Voxceleb2: Deep speaker recognition}</span><span class="p">,</span>
<span class="w">  </span><span class="na">author</span><span class="p">=</span><span class="s">{Chung, Joon Son and Nagrani, Arsha and Zisserman, Andrew}</span><span class="p">,</span>
<span class="w">  </span><span class="na">journal</span><span class="p">=</span><span class="s">{arXiv preprint arXiv:1806.05622}</span><span class="p">,</span>
<span class="w">  </span><span class="na">year</span><span class="p">=</span><span class="s">{2018}</span>
<span class="p">}</span>
</pre></div>
</div>
</section>
<section id="cnceleb">
<h3>CNCeleb<a class="headerlink" href="#cnceleb" title="Permalink to this heading"></a></h3>
<div class="highlight-bibtex notranslate"><div class="highlight"><pre><span></span><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">fan2020cn</span><span class="p">,</span>
<span class="w">  </span><span class="na">title</span><span class="p">=</span><span class="s">{Cn-celeb: a challenging chinese speaker recognition dataset}</span><span class="p">,</span>
<span class="w">  </span><span class="na">author</span><span class="p">=</span><span class="s">{Fan, Yue and Kang, JW and Li, LT and Li, KC and Chen, HL and Cheng, ST and Zhang, PY and Zhou, ZY and Cai, YQ and Wang, Dong}</span><span class="p">,</span>
<span class="w">  </span><span class="na">booktitle</span><span class="p">=</span><span class="s">{ICASSP 2020-2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}</span><span class="p">,</span>
<span class="w">  </span><span class="na">pages</span><span class="p">=</span><span class="s">{7604--7608}</span><span class="p">,</span>
<span class="w">  </span><span class="na">year</span><span class="p">=</span><span class="s">{2020}</span><span class="p">,</span>
<span class="w">  </span><span class="na">organization</span><span class="p">=</span><span class="s">{IEEE}</span>
<span class="p">}</span>
</pre></div>
</div>
</section>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="speaker_recognition_papers.html" class="btn btn-neutral float-left" title="Speaker Recognition Papers" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="python_api/modules.html" class="btn btn-neutral float-right" title="Python API Reference" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2024, wespeaker-team.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>